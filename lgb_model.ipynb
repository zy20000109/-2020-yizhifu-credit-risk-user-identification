{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coding: utf-8\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import lightgbm as lgb\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>label</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>provider</th>\n",
       "      <th>level</th>\n",
       "      <th>verified</th>\n",
       "      <th>using_time</th>\n",
       "      <th>regist_type</th>\n",
       "      <th>card_a_cnt</th>\n",
       "      <th>...</th>\n",
       "      <th>ip_nun_mean.1</th>\n",
       "      <th>ip_nun_std</th>\n",
       "      <th>ip_hour_nun_max</th>\n",
       "      <th>ip_hour_nun_min</th>\n",
       "      <th>ip_hour_nun_mean</th>\n",
       "      <th>ip_hour_nun_std</th>\n",
       "      <th>ip_min_nun_max</th>\n",
       "      <th>ip_min_nun_min</th>\n",
       "      <th>ip_min_nun_mean</th>\n",
       "      <th>ip_min_nun_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Train_00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>24871</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>24712</td>\n",
       "      <td>1</td>\n",
       "      <td>24712</td>\n",
       "      <td>...</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>0.577350</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.25000</td>\n",
       "      <td>0.452267</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.055556</td>\n",
       "      <td>0.232311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Train_00001</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>24889</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>24716</td>\n",
       "      <td>1</td>\n",
       "      <td>24719</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Train_00002</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>24963</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>24736</td>\n",
       "      <td>7</td>\n",
       "      <td>24712</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Train_00003</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>24840</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>24719</td>\n",
       "      <td>3</td>\n",
       "      <td>24712</td>\n",
       "      <td>...</td>\n",
       "      <td>1.909091</td>\n",
       "      <td>0.943880</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.03125</td>\n",
       "      <td>0.176777</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Train_00004</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>24871</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>24707</td>\n",
       "      <td>3</td>\n",
       "      <td>24712</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96197</th>\n",
       "      <td>TestB_19010</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>24865</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>24740</td>\n",
       "      <td>7</td>\n",
       "      <td>24712</td>\n",
       "      <td>...</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96198</th>\n",
       "      <td>TestB_12466</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>24908</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>24736</td>\n",
       "      <td>7</td>\n",
       "      <td>24712</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96199</th>\n",
       "      <td>TestB_05971</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>24993</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>24728</td>\n",
       "      <td>1</td>\n",
       "      <td>24706</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96200</th>\n",
       "      <td>TestB_16084</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>24908</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>24711</td>\n",
       "      <td>3</td>\n",
       "      <td>24719</td>\n",
       "      <td>...</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96201</th>\n",
       "      <td>TestB_07871</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>24859</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>24711</td>\n",
       "      <td>3</td>\n",
       "      <td>24712</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>96202 rows × 830 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              user  label  sex    age  provider  level  verified  using_time  \\\n",
       "0      Train_00000    0.0    1  24871         1      2         0       24712   \n",
       "1      Train_00001    1.0    1  24889         1      3         0       24716   \n",
       "2      Train_00002    0.0    1  24963         1      3         0       24736   \n",
       "3      Train_00003    0.0    1  24840         3      3         0       24719   \n",
       "4      Train_00004    0.0    1  24871         3      2         0       24707   \n",
       "...            ...    ...  ...    ...       ...    ...       ...         ...   \n",
       "96197  TestB_19010    NaN    1  24865         1      3         0       24740   \n",
       "96198  TestB_12466    NaN    1  24908         1      3         0       24736   \n",
       "96199  TestB_05971    NaN    1  24993         1      2         1       24728   \n",
       "96200  TestB_16084    NaN    1  24908         1      3         0       24711   \n",
       "96201  TestB_07871    NaN    1  24859         3      3         0       24711   \n",
       "\n",
       "       regist_type  card_a_cnt  ...  ip_nun_mean.1  ip_nun_std  \\\n",
       "0                1       24712  ...       1.500000    0.577350   \n",
       "1                1       24719  ...       1.000000    0.000000   \n",
       "2                7       24712  ...       1.000000         NaN   \n",
       "3                3       24712  ...       1.909091    0.943880   \n",
       "4                3       24712  ...       1.000000         NaN   \n",
       "...            ...         ...  ...            ...         ...   \n",
       "96197            7       24712  ...       1.500000    0.707107   \n",
       "96198            7       24712  ...       1.000000    0.000000   \n",
       "96199            1       24706  ...            NaN         NaN   \n",
       "96200            3       24719  ...       1.500000    0.707107   \n",
       "96201            3       24712  ...       1.000000    0.000000   \n",
       "\n",
       "       ip_hour_nun_max  ip_hour_nun_min  ip_hour_nun_mean  ip_hour_nun_std  \\\n",
       "0                  2.0              1.0           1.25000         0.452267   \n",
       "1                  1.0              1.0           1.00000         0.000000   \n",
       "2                  1.0              1.0           1.00000              NaN   \n",
       "3                  2.0              1.0           1.03125         0.176777   \n",
       "4                  1.0              1.0           1.00000              NaN   \n",
       "...                ...              ...               ...              ...   \n",
       "96197              1.0              1.0           1.00000         0.000000   \n",
       "96198              1.0              1.0           1.00000         0.000000   \n",
       "96199              NaN              NaN               NaN              NaN   \n",
       "96200              1.0              1.0           1.00000         0.000000   \n",
       "96201              1.0              1.0           1.00000         0.000000   \n",
       "\n",
       "       ip_min_nun_max  ip_min_nun_min  ip_min_nun_mean  ip_min_nun_std  \n",
       "0                 2.0             1.0         1.055556        0.232311  \n",
       "1                 1.0             1.0         1.000000        0.000000  \n",
       "2                 1.0             1.0         1.000000        0.000000  \n",
       "3                 1.0             1.0         1.000000        0.000000  \n",
       "4                 1.0             1.0         1.000000        0.000000  \n",
       "...               ...             ...              ...             ...  \n",
       "96197             1.0             1.0         1.000000        0.000000  \n",
       "96198             1.0             1.0         1.000000        0.000000  \n",
       "96199             NaN             NaN              NaN             NaN  \n",
       "96200             1.0             1.0         1.000000        0.000000  \n",
       "96201             1.0             1.0         1.000000        0.000000  \n",
       "\n",
       "[96202 rows x 830 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=pd.read_csv(\"F:/data.csv\")\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kfold_stats_feature(train, test, feats, k):\n",
    "    folds = StratifiedKFold(n_splits=k, shuffle=True, random_state=2020)  # 这里最好和后面模型的K折交叉验证保持一致\n",
    "\n",
    "    train['fold'] = None\n",
    "    for fold_, (trn_idx, val_idx) in enumerate(folds.split(train, train['label'])):\n",
    "        train.loc[val_idx, 'fold'] = fold_\n",
    "\n",
    "    kfold_features = []\n",
    "    for feat in feats:\n",
    "        nums_columns = ['label']\n",
    "        for f in nums_columns:\n",
    "            colname = feat + '_' + f + '_kfold_mean'\n",
    "            kfold_features.append(colname)\n",
    "            train[colname] = None\n",
    "            for fold_, (trn_idx, val_idx) in enumerate(folds.split(train, train['label'])):\n",
    "                tmp_trn = train.iloc[trn_idx]\n",
    "                order_label = tmp_trn.groupby([feat])[f].mean()\n",
    "                tmp = train.loc[train.fold == fold_, [feat]]\n",
    "                train.loc[train.fold == fold_, colname] = tmp[feat].map(order_label)\n",
    "                # fillna\n",
    "                global_mean = train[f].mean()\n",
    "                train.loc[train.fold == fold_, colname] = train.loc[train.fold == fold_, colname].fillna(global_mean)\n",
    "            train[colname] = train[colname].astype(float)\n",
    "\n",
    "        for f in nums_columns:\n",
    "            colname = feat + '_' + f + '_kfold_mean'\n",
    "            test[colname] = None\n",
    "            order_label = train.groupby([feat])[f].mean()\n",
    "            test[colname] = test[feat].map(order_label)\n",
    "            # fillna\n",
    "            global_mean = train[f].mean()\n",
    "            test[colname] = test[colname].fillna(global_mean)\n",
    "            test[colname] = test[colname].astype(float)\n",
    "    del train['fold']\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lgb_model(train, target, test, k):\n",
    "    feats = [f for f in train.columns if f not in ['user', 'label']]\n",
    "    print('Current num of features:', len(feats))\n",
    "    folds = StratifiedKFold(n_splits=k, shuffle=True, random_state=2020)\n",
    "    oof_probs = np.zeros(train.shape[0])\n",
    "    output_preds = 0\n",
    "    offline_score = []\n",
    "    feature_importance_df = pd.DataFrame()\n",
    "    parameters = {\n",
    "        'learning_rate': 0.05,\n",
    "        'boosting_type': 'gbdt',\n",
    "        'objective': 'binary',\n",
    "        'metric': 'auc',\n",
    "        'num_leaves': 63,\n",
    "        'feature_fraction': 0.8,\n",
    "        'bagging_fraction': 0.8,\n",
    "        'min_data_in_leaf': 20,\n",
    "        'verbose': -1,\n",
    "        'nthread': 8\n",
    "    }\n",
    "\n",
    "    for i, (train_index, test_index) in enumerate(folds.split(train, target)):\n",
    "        train_y, test_y = target[train_index], target[test_index]\n",
    "        train_X, test_X = train[feats].iloc[train_index, :], train[feats].iloc[test_index, :]\n",
    "\n",
    "        dtrain = lgb.Dataset(train_X,\n",
    "                             label=train_y)\n",
    "        dval = lgb.Dataset(test_X,\n",
    "                           label=test_y)\n",
    "        lgb_model = lgb.train(\n",
    "                parameters,\n",
    "                dtrain,\n",
    "                num_boost_round=5000,\n",
    "                valid_sets=[dval],\n",
    "                early_stopping_rounds=100,\n",
    "                verbose_eval=100,\n",
    "        )\n",
    "        oof_probs[test_index] = lgb_model.predict(test_X[feats], num_iteration=lgb_model.best_iteration)\n",
    "        offline_score.append(lgb_model.best_score['valid_0']['auc'])\n",
    "        output_preds += lgb_model.predict(test[feats], num_iteration=lgb_model.best_iteration)/folds.n_splits\n",
    "        print(offline_score)\n",
    "        # feature importance\n",
    "        fold_importance_df = pd.DataFrame()\n",
    "        fold_importance_df[\"feature\"] = feats\n",
    "        fold_importance_df[\"importance\"] = lgb_model.feature_importance(importance_type='gain')\n",
    "        fold_importance_df[\"fold\"] = i + 1\n",
    "        feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)\n",
    "    print('OOF-MEAN-AUC:%.6f, OOF-STD-AUC:%.6f' % (np.mean(offline_score), np.std(offline_score)))\n",
    "    print('feature importance:')\n",
    "    print(feature_importance_df.groupby(['feature'])['importance'].mean().sort_values(ascending=False).head(15))\n",
    "    return output_preds, oof_probs, np.mean(offline_score),feature_importance_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current num of features: 832\n",
      "Train until valid scores didn't improve in 100 rounds.\n",
      "[100]\tvalid_0's auc: 0.737829\n",
      "[200]\tvalid_0's auc: 0.73701\n",
      "Early stopping, best iteration is:\n",
      "[106]\tvalid_0's auc: 0.738497\n",
      "[0.7384967813610117]\n",
      "Train until valid scores didn't improve in 100 rounds.\n",
      "[100]\tvalid_0's auc: 0.735191\n",
      "[200]\tvalid_0's auc: 0.734821\n",
      "Early stopping, best iteration is:\n",
      "[114]\tvalid_0's auc: 0.735624\n",
      "[0.7384967813610117, 0.7356241080457369]\n",
      "Train until valid scores didn't improve in 100 rounds.\n",
      "[100]\tvalid_0's auc: 0.72694\n",
      "[200]\tvalid_0's auc: 0.726645\n",
      "Early stopping, best iteration is:\n",
      "[145]\tvalid_0's auc: 0.72903\n",
      "[0.7384967813610117, 0.7356241080457369, 0.7290300473967176]\n",
      "Train until valid scores didn't improve in 100 rounds.\n",
      "[100]\tvalid_0's auc: 0.728103\n",
      "[200]\tvalid_0's auc: 0.729544\n",
      "Early stopping, best iteration is:\n",
      "[192]\tvalid_0's auc: 0.729653\n",
      "[0.7384967813610117, 0.7356241080457369, 0.7290300473967176, 0.7296533083380494]\n",
      "Train until valid scores didn't improve in 100 rounds.\n",
      "[100]\tvalid_0's auc: 0.72525\n",
      "[200]\tvalid_0's auc: 0.723575\n",
      "Early stopping, best iteration is:\n",
      "[100]\tvalid_0's auc: 0.72525\n",
      "[0.7384967813610117, 0.7356241080457369, 0.7290300473967176, 0.7296533083380494, 0.7252500707413696]\n",
      "OOF-MEAN-AUC:0.731611, OOF-STD-AUC:0.004785\n",
      "feature importance:\n",
      "feature\n",
      "user_amount_cnt_7d                     8636.185623\n",
      "w2c_op_channel_4_min                   4734.826349\n",
      "product7_fail_ratio                    3759.569565\n",
      "w2c_op_channel_0_min                   2563.370318\n",
      "product7_fail_cnt                      1946.100966\n",
      "user_type1_45a1168437c708ff_min_day    1942.046070\n",
      "user_amount_cnt_6h                     1824.989926\n",
      "province_label_kfold_mean              1686.463399\n",
      "user_amount_med_6h                     1676.463068\n",
      "city_label_kfold_mean                  1649.756151\n",
      "user_amount_cnt_15d                    1635.459633\n",
      "w2c_trans_amount_2_mean                1572.195898\n",
      "count_amount_trans_max                 1524.786096\n",
      "service3                               1423.269389\n",
      "woe_of_age                             1365.717445\n",
      "Name: importance, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "data['city_level'] = data['city'].map(str) + '_' + data['level'].map(str)\n",
    "data['city_balance_avg'] = data['city'].map(str) + '_' + data['balance_avg'].map(str)\n",
    "train = data[~data['label'].isnull()].copy()\n",
    "target = train['label']\n",
    "test = data[data['label'].isnull()].copy()\n",
    "\n",
    "target_encode_cols = ['province', 'city', 'city_level', 'city_balance_avg']\n",
    "train, test = kfold_stats_feature(train, test, target_encode_cols, 5)\n",
    "train.drop(['city_level', 'city_balance_avg'], axis=1, inplace=True)\n",
    "test.drop(['city_level', 'city_balance_avg'], axis=1, inplace=True)\n",
    "\n",
    "lgb_preds, lgb_oof, lgb_score, fea_df = lgb_model(train=train, target=target, test=test, k=5)\n",
    "\n",
    "sub_df = test[['user']].copy()\n",
    "sub_df['prob'] = lgb_preds\n",
    "#sub_df.to_csv('F:/sub.csv', index=False)\n",
    "# fea_df.to_csv('F:/feature.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_df.sort_values(by=\"user\")[24315:].to_csv(\"F:/sub.csv\",index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
